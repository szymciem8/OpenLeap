\chapter{Streszczenie}

%%Faktyczne streszczenie

\quad Praca inżynierska pod tytułem \enquote{System wizyjny do śledzenia ruchomych obiektów} łączy tematykę wizji komputerowej oraz algorytmów uczenia maszynowego. 

\quad Praca skupia się na stworzeniu wygodnej w użyciu oraz powszechnie dostępnej biblioteki umożliwiającej wykorzystanie gestów, pozycji dłoni, obrotu dłoni oraz odległości między wybranymi palcami jako elementów sterujących w dowolnym projekcie napisanym w języku Python. 

\quad Do napisania pracy wykorzystano biblioteki języka Python o otwartym kodzie źródłowym, głównie OpenCV, MediaPipe oraz SciKit-Learn. 

\quad Całość projektu jest dostępna na platformie PyPi, która jest standardowym repozytorium paczek języka Python. Korzysta z niego menedżer paczek o nazwie \textbf{pip}, który jest programem automatycznie pobieranym podczas instalacji interpretera języka. Na głównej stronie paczki znajduje się dokumentacja oraz instrukcja instalacji i użytkowania. 

\quad Użytkownik paczki ma możliwość stworzenia własnych modeli rozpoznających gesty za pomocą interaktywnej instrukcji napisanej w Jupyter Notebook. 

\addcontentsline{toc}{chapter}{Streszczenie}

%\cleardoublepage

\pagestyle{NumeryStronNazwyRozdzialow}


% Praca inżynierska pod tytułem "System wizyjny do śledzenia ruchomych obiektów" łączy tematykę wizji komputerowej oraz algorytmów uczenia maszynowego. 

% Praca skupia się na stworzeniu wygodnej w użyciu oraz powszechnie dostępnej biblioteki umożliwiającej wykorzystanie gestów, pozycji dłoni, obrotu dłoni oraz odległości między wybranymi palcami jako elementów sterujących w dowolnym projekcie napisanym w języku Python. 

% Do napisania pracy wykorzystano biblioteki języka Python o otwartym kodzie źródłowym, głównie OpenCV, MediaPipe oraz SciKit-Learn. 

% Całość projektu jest dostępna na platformie PyPi, która jest standardowym repozytorium paczek języka Python. Korzysta z niego menedżer paczek o nazwie pip, który jest programem automatycznie pobieranym podczas instalacji interpretera języka. Na głównej stronie paczki znajduje się dokumentacja oraz instrukcja instalacji i użytkowania. 

% Użytkownik paczki ma możliwość stworzenia własnych modeli rozpoznających gesty za pomocą interaktywnej instrukcji napisanej w Jupyter Notebook. 