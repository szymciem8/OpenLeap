\chapter{[Właściwy dla kierunku - np.Specyfikacja wewnętrzna]}
Jeśli to Specyfikacja wewnętrzna:
\begin{itemize}
\item przedstawienie idei
\item architektura systemu
\item opis struktur danych (i organizacji baz danych)
\item komponenty, moduły, biblioteki, przegląd ważniejszych klas (jeśli występują)
\item przegląd ważniejszych algorytmów (jeśli występują)
\item szczegóły implementacji wybranych fragmentów, zastosowane wzorce projektowe
\item diagramy UML
\end{itemize}


\begin{itemize}
    \item wymagania funkcjonalne i niefunkcjonalne
    \item przypadki użycia (diagramy UML) - dla prac, w których mają zastosowanie
    \item opis narzędzi, metod eksperymentalnych, metod modelowania itp.
    \item metodyka pracy nad projektowaniem i implementacją - dla prac, w których ma to zastosowanie
    \end{itemize}
    
    \section{Budowa klasy}

    \quad Schemat UML itd

    \section{Struktury danych}
    \subsection{Dataclass}

    \quad Strukura typu \textbf{Dataclass} pozwala na stworznie struktury podobnej do \textbf{struct} istniejącej w języku programowania \textbf{C}. Taka klasa pozwala na storzenie obiektu składającego się jedynie z atrybutów wymaganych do opisue elementów klasy kontrolera. Dodatkowym atutem takiej klasy jest możliwość prostego odczytu zapisanych danych, korzystając z operatora kropki, a nie z operatrów opisujących słownik lub listę. 

    \begin{lstlisting}[language=python]
        @dataclass
        class Data:
            x : float = 0
            y : float = 0
            z : float = 0
            distance: float = 0.0
            angle: float = 0.0
            gesture: str = None
    \end{lstlisting}

    \quad W języku Python stworzenie klasy typu \textbf{dataclass} zaczyna się od zapisania dekoratora. W tym wypadku nie jest wymagana funkcja inicjalizująca obiekt, czyli \textbf{\_\_init\_\_}. Parametetry początkowe można podać w chwili tworzenia obiektu, lub później. W programie zostały przypisane wartości początkowej, tak jak w przykładzie powyżej. 

    \subsection{Słownik}

    \quad Instancja stworzonego typu \textbf{Data} zostnie zainicjowana dla każdej dłoni (lewej oraz prawej). Te instacje zostaną zapisane w słowniku. 

    \begin{lstlisting}[language=python]
        data = {'right':Data(), 'left':Data()}
    \end{lstlisting}

    \quad Taka konstrukcja pozwoli użytkownikowi w prosty i przejrzysty sposób na odnajodowania potrzebnych wartości oraz informacji. 

    \subsection{Pickle}
    \quad Modele matematyczne, które zostaną wytrenowane muszą zostać zapisane, tak aby można było je wykorzystać ponownie. Z tego powodu został wykorzystany plik typi \textbf{pickle}, który umożliwia zapis zmiennych oraz obiektów w postaci binarnej. Dzięki czemu można je wykorzystać ponownie pomimo restartu programu. 

    \section{Rozpoznawanie dłoni}
    
    \quad Pierwszym elementem projektu jest rozpoznanie dłoni poprzez wyznacznie pozycji elementów charakterystycznych. Pozycja każdego z tych elementów, jak już zostało to opisane, jest względna według lewego górnego rogu obrazu kamery. 



    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%% OPEN CV %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \subsection{OpenCV - przygotowanie obrazu z kamery}
    
    \quad Poprawne działanie modelu MediaPipe wymaga odpowiedniego przygotowania obrazu kamery. Działanie kontrolerolera odbywa się poprzez główną metodę \textbf{main()}.
    
    \begin{figure}[H]
        \begin{center}
            \includegraphics[width=10cm]{../images/image_processing.png}
            \caption{Elementy charakterystyczne dłoni}
        \end{center}
    \end{figure}

    \quad Metoda \textbf{main()} jest główną funkcją, w której dokonywane są obliczenia oraz przeszktałcenia pozwalające na obliczenie obrotu dłonie, odległości między wybranymi palcami oraz na wykrycie gestu. 
    
    % \inputminted[firstline=51, lastline=52]{python}{../OpenLeap.py}
    
    % \lstinputlisting[language=python, firstline=51, lastline=52]{../OpenLeap.py}
    
    \quad W pierwszym kroku tworzymy instancję klasy \textbf{VideoCapture} biblioteki \textbf{OpenCV}, która pozwoli na odczytywanie obrazu kamery. 
    
    % \lstinputlisting[language=python, firstline=272, lastline=297]{../OpenLeap.py}
    
    % \inputminted[firstline=272, lastline=297]{python}{../OpenLeap.py}
    
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %%%%%%%%%%%%%%%%%%%%%%%%%%%% MEDIA PIPE %%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    
    \subsection{MediaPipe - Elementy charakterystyczne}
    
    \quad Biblioteka MediaPipe o otwartym źródle, udostępnia wieloplatformowe oraz konfigurowalne rozwiązania wykrzustujące uczenie maszynowe w dziedzienie rozpoznawania, segmentacji oraz klasyfikacji obiektów wizji komputerowej. Niektórymi z rozwiązań są:
    
    \begin{itemize}
        \item Rozpoznawanie twarzy
        \item Segmentacjia włosów oraz twarzy
        \item Rozpoznawnie oraz określanie rozmiarów obiektów trójwymiarowych 
              na podstawie obrazu dwuwymiarowego. 
    \end{itemize}
    
    \quad Model modułu MediaPipe pozwala na wyznaczenie pozycji 21 elementów charakterystycznych dłoni. Współrzędne X i Y są znomralizowane względem rozdzielczości obrazu kamery. Współrzędna X względem liczby pikseli w osi X, a współrzędna Y względem liczby pikseli w osi Y. Oś Z jest prostopadła do osi X i Y, z punktem początkowym w punkcie określającym pozycję nadgarstka. Współrzędna Z jest znormalizowana względem szerokości obrazu kamery, tak jak współrzędna X. 
    
    \begin{figure}[H]
    \begin{center}
        \includegraphics[width=15cm]{../images/hand_landmarks.png}
        \caption{Elementy charakterystyczne dłoni}
    \end{center}
    \end{figure}
    
    \quad Pozycje nadgarstka, paliczków oraz stawów dłoni zostaną wykorzystane do obliczenia obrotu dłoni względem punkut 0 oraz do wytrenowania modeli uczenia maszynowego, których zadaniem będzie rozpoznawnie wybranych gestów. 
    
    \subsection{Generowanie grafiki dłoni}
    
    \quad Generowanie grafiki nałożonej na daną dłoń wykonuje się przy pomocy przygotowanej funkcji biblioteki MediaPipe, która współpracuje z OpenCV.   

    \section{Pomiary oraz inne ważne elementy}

    \subsection{Pozycja dłoni}

    \subsection{Obrót dłoni}

    \subsection{Odległość między palcami}
    
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %%%%%%%%%%%%%%%%%%%%%%%%%%% SciKit Learn %%%%%%%%%%%%%%%%%%%%%%%%%%%
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    
    
    % \section{Uczenie Maszynowe}

    \section{Rozpoznawanie gestów}
    
    \quad SciKit Learn to biblioteka, która oferuje różnego typu metody uczenia maszynowego. Biblioteka zawiera algorytmy klasyfikacji, regresjii oraz analizy skupień. Przykładowym algorytmami w bibliotece są:
    \begin{itemize}
        \item Las losowy - polegająca na konstruowaniu wielu drzew decyzyjnych w czasie uczenia. 
        \item Algorytm centroidów - algorytm wykorzystywany w analizie skupień.
        \item Maszyna wektorów nośnoych - algorytm klasyfikujący, często wykorzystywany w procesie rozpoznawania obrazów. 
    \end{itemize}
    O wszystkich dostępnych algorytmach informacje można znaleźć w ogólnodostępnej dokumentacji biblioteki. 
    
    \subsection{Przygotowanie modeli uczenia maszynowego}
    \quad Celem programu będzie stworzenie modeli matematycznych przy pomocy metod uczenia maszynowego, których celem będzie rozpoznawanie gestów dłoni. Proces tworzenie takiego modelu można podzielić na trzy kroki przedstawione na schemacie 6.3. 

    \begin{figure}[H]
        \begin{center}
            \includegraphics[width=8cm]{../images/full_algorithm.png}
            \caption{Ogólny algorytm przygotowania modeli uczenia maszynowego}
        \end{center}
    \end{figure}

    \quad Całość programu została napisana w notatniku Jupyter. Pozwala to na wykonanie pewnych części programu osobno, niezależnie od reszty programu. W praktyce każdy blok opisany w powyższym schemacie UML ma swoje odwzorowanie w notatniku. Na przykład, część zapisująca współrzędne do pliku będzie wykonywana tyle razy ile jest gestów do wytrenowania. 

    \subsection{Zebranie danych}
    \quad Algorytm zebrania danych polega na pobraniu współrzędnych oszacowanych przez model MediaPipe. Należy pamiętać o tym, że środek układu współrzędnych znajduje się lewym górnym rogu obrazu kamery. Oznacza to, że współrzędne w tej postaci nie nadają się do wyuczenia modelu matematycznego. Gest nie powinnien być rozpoznawany na podstawie pozycji dłoni w obrazie lub jej odległości od kamery. Należy się tych zależności pozbyć. 
    
    \begin{figure}[H]
        \begin{center}
            \includegraphics[width=10cm]{../images/get_data.png}
            \caption{Ogólny algorytm przygotowania modeli uczenia maszynowego}
        \end{center}
    \end{figure}
    
    \quad Gest dłoni, można scharakteryzować na podstawie pozycji elementów dłoni. Podstawowym problemem jest fakt, że pozycje elementów charakterystycznych są opisane względem układu współrzędnych, którego środek znajduje się w lewym górnym rogu obrazu pobranego z kamery. Pozycja dłoni na obrazie nie ma żadnego znaczenia w kwestii określania gestu. Poprawnie przygotowane pozycje elementów powinnny zostać pozbawione zależności od pozycji dłoni względem obrazu. 
    \quad Przygotowanie danych do przetworzenia będzie wymagało paru opercaji matematycznych. W takim wypadku należy przprowadzić transformację, tutaj akurat przesunięcie układu współrzędnych do pozycji nadgarstka. Taka operacja pozwoli na opis pozycji elementów względem nagarstka. Ostatecznie pozbywamy się pozycji nadarstka z wektora danych, ponieważ jest ona środkiem nowego układu współrzędnych. 
    
    \quad \textbf{Macierz przesunięcia}
    
    \begin{equation*}
        M_p = 
        \begin{bmatrix}
        1 & 0 & 0 & -x_0 \\
        0 & 1 & 0 & -y_0 \\
        0 & 0 & 1 & -z_0 \\
        0 & 0 & 0 & 1
        \end{bmatrix}
    \end{equation*}

    \quad Tak naprawdę, przesunięcie układu współrzędnych w osi Z nie będzie miało miejsca. Wartości współrzędnej Z reszty elementów, oprócz elementu z indeksem równym 0, czyli nadgarstka, są określane właśnie nadgarstka. Dlatego też, macierz przesunięcia w osi Z jest równa 0. 

    \begin{equation*}
        M_p = 
        \begin{bmatrix}
        1 & 0 & 0 & -x_0 \\
        0 & 1 & 0 & -y_0 \\
        0 & 0 & 1 & 0 \\
        0 & 0 & 0 & 1
        \end{bmatrix}
    \end{equation*}
    
    \quad Aby dane mogły zostać zinterpretowane przez algorytmy ucznenia maszynowego muszą one zostać przedstawione w postaci jednowymiarowej. Aktualna postać macierzy przedstawiającej wpółrzędne elementów charakterystycznych ma następującą postać. Indeksy współrzędnych są równoznaczne z indeksami elementów dłoni. 
    
    \begin{equation*}
        M_p = 
        \begin{bmatrix}
        x_1' & y_1' & z_1' \\
        x_2' & y_2' & z_2' \\
         & \vdots &     \\
        x_{21}' & y_{21}' & z_{21}'
        \end{bmatrix}
    \end{equation*}
    
    Dane w postaci jednowymiarowej mają postać następującego wektora. 
    
    \begin{equation*}
        A_f=
        \begin{bmatrix}
            x_1 & y_1 & z_1 & x_2 & y_2 & \cdots & y_{21} & z_{21}
        \end{bmatrix}
    \end{equation*}
    
    
    \quad Drugim krokiem jest uniezależnienie pozycji elementów od odległości dłoni od kamery. Najprostszym rozwiązaniem jest normalizacja wektora danych względem największej bezwzględnej wartości. 
    
    \quad \textbf{Normalizacja}
    
    % \begin{equation*}
    %     A_n=
        % \begin{bmatrix}
        %     x_1 & y_1 & z_1 & x_2 & y_2 & \cdots & y_{21} & z_{21}
        % \end{bmatrix}
    % \end{equation*}
    
    
    \begin{equation*}
        A_n=\dfrac{A_f}{max(abs(A_f))}
    \end{equation*}
    
    \quad Każdy nowy wektor zostaje zapisany do pliku CSV z odpwowiednią etykietą. Zebrane dane posłużą do wytrenowania algorytmów uczenia maszynowego.     
    
    \subsection{Budowa pliku CSV}
    \quad Dane zapisane w pliku CSV opisują przykładowe współrzędne wszysktich elementów dłoni wraz z przypisaną etykietą oznaczającą gest. 

    \subsection{Metody klasyfikacji - uczenie maszynowe}
    
    \quad Przygotowane dane zostają odczytane z pliku CSV. W pierwszym kroku należy rozdzielić je na dwie części: współrzędne (dane wejściowe) oraz etykiety (dane wyjściowe). W kolejnym kroku należy te dwie grupy podzielić na grupę trenującą i grupę testową. Zadaniem grupy testowej będzie trenowanie wybranych modeli matematycznych, a grupy testowej przetestowanie ich dokładności. 

    \begin{figure}[H]
        \begin{center}
            \includegraphics[width=11cm]{../images/train_models.png}
            \caption{Ogólny algorytm przygotowania modeli uczenia maszynowego}
        \end{center}
    \end{figure}
    
    \quad W celu wybrania najlepszej metody klasyfikacji, zostnie wybranych kilka algorytmów. Każdy z nich stworzy swój model, a ostatecznie zostanie sprawdzona ich poprawności z wykorzystaniem grupy testowej. Model z najepszym wynikiem zostanie zapisany do pliku typu \textbf{pickle}. W języku Python pliki typu \textbf{pickle} pozwalają na zapis zmiennych, obiektów lub innych struktur danych, które mają zostać wykorzystane w po zakończeniu programu. 

    \subsection{Wybrane algorytmy klasyfikujące}

    \quad Do wytrenowania modeli uczenia maszynowego z biblioteki SciKit Learn zostały wybrane następujące algorytmy. 

    \begin{itemize}
        \item Logistic Regression
        \item Nearest Centroid 
        \item Decision Tree Classifier 
        \item Random Forest Classifier 
        \item SGD Classifier
        \item Gradient Boosting Classifier
        \item MPL Classifier
    \end{itemize}

    \subsection{Badanie dokładności każdego z algorytmów}
    
    \subsection{Ponowne wykorzystanie modelu}
    
    \quad Gotowy model pobieramy i testujemy w przykładowym programie. 
    
    \section{Paczka PyPi}

    \subsection{Budowa paczki}
    
    \quad Ostatecznym krokiem jest przygotowanie programu w formie paczki, która zostanie udostępniona na platformie PyPi. Wygama to przygotowania odpowiednich plików konfiguracyjnych oraz zostosowania stosownych narzędzi do stworznie pliku \textbf{wheel} oraz \textbf{tar}. 
    
    \subsection{Struktura Paczki}
    \quad Pierwszm krokiem jest przygotowanie odpowiedniej struktury paczki. Do tego celu został stworzony folder o poniższej strukturze. W tym folderze znajdują się wszystkie potrzebne elementy paczki. W podfolderze o tej samej nazwie znajduje się główna części modułu, czyli plik .py, w którym zapisana jest klasa OpenLeap. Dodatkowo w tym folderze znajdują się pliki typu \textbf{pickle}, w których zapisane są modele rozpoznające gesty.
    
    \begin{figure}
    \centering
        \begin{minipage}{7cm}
            \dirtree{%
            .1 openleap.
            .2 openleap.
            .3 \hyperref[openleap-file1]{\_\_init\_\_.py}.
            .3 \hyperref[openleap-file2]{OpenLeap.py}.
            .3 \hyperref[openleap-file3]{gesture\_recognition.pkl}.
            .3 \hyperref[openleap-file4]{sign\_language\_alphabet.pkl}.
            .2 LICENSE.
            .2 MANIFEST.
            .2 README.md.
            .2 setup.py.
            } 
        \end{minipage}
        \caption{Struktura paczki PyPi}
    \end{figure}
    
    \subsection{Pliki Konfiguracyjne}
    \quad Pliki setup.py oraz MANIFEST są plikami, które odpowiadają za konfigurację oraz opis paczki. W pliku setup.py zapisany jest numer aktualnej wersji, autor, kontakt do autora, nazwa paczki itp. 
    
    \quad 
    
    
    % \subsection{Plik setup.py}
    \subsection{Załadowanie paczki do repozytorium}
    
    \quad Przed załadowaniem paczki do repozytorium, należy stworzyć zapakowaną paczkę źródłową, na przykład typu .tar oraz plik typu WHEEL. Oba pliki spełniają tą samą funkcję, czyli przechowywnie niezbędnych elementów paczki oraz umożliwiają ich instalację na systemie użytkownika. Plik WHEEL pozwala na dużo szybszy proces instalacji niż instalacja ze źródła, czyli paczki typu .tar. 
